package asmeta.evotest.experiments;

import java.io.File;
import java.io.OutputStream;
import java.io.PrintStream;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.asmeta.parser.ASMParser;
import org.asmeta.simulator.RuleEvaluator;
import org.asmeta.simulator.main.Simulator;
import org.asmeta.xt.validator.AsmetaV;
import org.asmeta.xt.validator.RuleEvalWCov;
import org.asmeta.xt.validator.SimulatorWCov;

import asmeta.AsmCollection;
import asmeta.evotest.experiments.model.ModelDataCollector;
import asmeta.evotest.experiments.scenario.ScenarioDataCollector;
import asmeta.evotest.experiments.scenario.ScenarioValidator;
import asmeta.evotest.experiments.scenario.ValidationDataCollector;
import asmeta.evotest.experiments.utils.CsvManager;
import asmeta.evotest.experiments.utils.YamlManager;
import asmeta.mutation.mutationscore.MutatedScenarioExecutor;

public class AnalysisRunner {
	private static final String DATA_CSV = "data.csv";

	private static final Logger LOG = Logger.getLogger(AnalysisRunner.class);

	public enum STATUS {
		OK("OK"),
		NO_VALID_SCENARIOS("NO_VALID_SCENARIOS"),
		METADATA_ERROR("META_ERR"),
		ASM_PARSE_ERROR("ASM_PARSE_ERR"),
		MODEL_DATA_ERROR("MODEL_DATA_ERR"),
		SCENARIO_DATA_ERROR("SCENARIO_DATA_ERR"),
		COVERAGE_ERROR("COVERAGE_ERR"),
		DATA_AGGREGATION_ERROR("DATA_AGGREGATION_ERR"),
		MUTATION_ERROR("MUTATION_ERR"),
		REMAINING_PROBLEMATIC_SCENARIOS("REMAINING_PROBLEMATIC_SCENARIOS");

		private final String csvValue;

		STATUS(String comment) {
			this.csvValue = comment;
		}

		public String getCsvValue() {
			return csvValue;
		}
	}

	/**
	 * Entry point for aggregating scenario-generation and validation results into a
	 * CSV. Given a base directory (containing subfolders {@code randomtests/},
	 * {@code atgttests/}, {@code evoavallatests/}), walks each directory, then each
	 * generated scenario suite directory, and for each suite run validation and
	 * write model, scenarios, and validation data to csv.
	 *
	 * @param args command-line arguments
	 *             <ul>
	 *             <li>{@code args[0]} – the base directory to scan</li>
	 *             <li>{@code args[0]} – {@code --shuffle}: optional flag that
	 *             enables shuffled, non-deterministic execution of choose rules
	 *             when present; if omitted, execution is deterministic</li>
	 *             </ul>
	 */
	public static void main(String[] args) {
		// Set logging and silence stdout
		LOG.setLevel(Level.INFO);
		Logger.getLogger(RuleEvaluator.class).setLevel(Level.ERROR);
		Logger.getLogger(Simulator.class).setLevel(Level.ERROR);
		Logger.getLogger(RuleEvalWCov.class).setLevel(Level.ERROR);
		Logger.getLogger(SimulatorWCov.class).setLevel(Level.ERROR);
		Logger.getLogger(AsmetaV.class).setLevel(Level.ERROR);
		ASMParser.getResultLogger().setLevel(Level.ERROR);
//		System.setOut(new PrintStream(OutputStream.nullOutputStream()));

		// Validate input directory argument
		if (args.length < 1)
			LOG.error("Missing argument: directory to search for scenarios.");
		String baseDir = args[0];
		boolean shuffle;
		if (args.length == 1) {
			shuffle = false;
		} else {
			if (args[1].equals("--shuffle")) {
				shuffle = true;
			} else {
				LOG.error("Error in second argument: it must be --shuffle or not be present.");
				return;
			}
		}

		// Prepare the output CSV (clean sibling temp if present CSVs and write header)
		String csvPath = baseDir + File.separator + DATA_CSV;
		CsvManager csvManager;

		try {
			csvManager = new CsvManager(csvPath);
			csvManager.clean();
			csvManager.setup();
		} catch (Throwable t) {
			LOG.error("Error while deleting temp files or writing header to " + csvPath + "\n"
					+ t.getClass().getSimpleName() + ": " + t.getMessage());
			t.printStackTrace();
			return;
		}

		// Iterate over approach directories (randomtests/, atgttests/, evoavallatests/)
		File[] approachDirs = new File(baseDir).listFiles();
		for (File approachDir : approachDirs) {
			if (approachDir.isDirectory() && approachDir.listFiles().length > 0) {
				String approach = approachDir.getName().replace("tests", "");
				LOG.info("Running analysis on scenarios generated by " + approach + ".");
				// Iterate over individual scenario-suite directories
				File[] scenarioDirs = approachDir.listFiles();
				for (File scenarioDir : scenarioDirs) {
					if (scenarioDir.isDirectory()) {
						Map<String, String> modelData = new HashMap<>();
						Map<String, Integer> avallaData = new HashMap<>();
						Map<String, String> covData = new HashMap<>();
						Map<String, String> mutationData = new HashMap<>();
						String asmName = scenarioDir.toString();
						asmName = asmName.substring(asmName.lastIndexOf("_") + 1);
						String asmPath = "";
						STATUS status = STATUS.OK;
						float execTime = 0;
						int nScenario = 0;
						int valErrors = 0;
						int failing = 0;

						LOG.info("\nAnalysing " + scenarioDir);

						// Find and read the metadata YAML
						try {
							LOG.info("Reading metadata YAML file...");
							File[] yamlFiles = scenarioDir
									.listFiles(file -> file.isFile() && file.getName().toLowerCase().endsWith(".yaml"));
							File metadataFile = yamlFiles[0];
							Map<String, Object> metadata = YamlManager.load(metadataFile);
							asmName = (String) metadata.get(YamlManager.ASM_NAME);
							asmPath = (String) metadata.get(YamlManager.ASM_PATH);
							Object execTimeValue = metadata.get(YamlManager.EXEC_TIME);
							if (execTimeValue instanceof Number)
								execTime = ((Number) execTimeValue).floatValue();
							else
								execTime = Float.NaN;
						} catch (Throwable t) {
							LOG.error("Error while trying to access metadata YAML file.\n"
									+ t.getClass().getSimpleName() + ": " + t.getMessage());
							status = STATUS.METADATA_ERROR;
							writeToCsv(csvManager, modelData, avallaData, covData, mutationData, asmName, asmPath,
									approach, status, execTime, nScenario, failing, valErrors);
							continue;
						}

						// Resolve ASM absolute path and parse the model
						AsmCollection asm;
						try {
							LOG.info("Parsing " + asmName + "...");
							Path basePath = Path.of(scenarioDir.getCanonicalPath());
							String asmAbsolutePath = basePath.resolve(Paths.get(asmPath)).normalize().toAbsolutePath()
									.toString();
							asm = ASMParser.setUpReadAsm(new File(asmAbsolutePath));
						} catch (Throwable t) {
							// It should never happens: if the asm is not parsable, test generation would
							// have failed
							LOG.error("Error while parsing " + asmName + ".\n" + t.getClass().getSimpleName() + ": "
									+ t.getMessage());
							status = STATUS.ASM_PARSE_ERROR;
							writeToCsv(csvManager, modelData, avallaData, covData, mutationData, asmName, asmPath,
									approach, status, execTime, nScenario, failing, valErrors);
							continue;
						}

						// Collect model data
						try {
							LOG.info("Collecting model data...");
							modelData = ModelDataCollector.collectModelData(asm);
						} catch (Throwable t) {
							LOG.error("Error while collecting model data.\n" + t.getClass().getSimpleName() + ": "
									+ t.getMessage());
							status = STATUS.MODEL_DATA_ERROR;
							writeToCsv(csvManager, modelData, avallaData, covData, mutationData, asmName, asmPath,
									approach, status, execTime, nScenario, failing, valErrors);
							continue;
						}

						// Run validation to identify and delete failing scenarios and scenario that
						// results in validation error
						LOG.info("Removing problematic scenarios...");
						String dir = scenarioDir.toString();
						File[] files = new File(dir).listFiles();
						for (File f : files) {
							String name = f.getName();
							// Validate and rename only the .avalla files generated during this iteration
							if (f.isFile() && name.endsWith(AsmetaV.SCENARIO_EXTENSION)) {
								try {
									List<String> failingScenarios = AsmetaV.execValidation(f.toString(), true, false);
									if (failingScenarios.size() > 0) {
										LOG.info("removing " + name + ": validation failed.");
										failing++;
										f.delete();
									}
								} catch (Throwable e) {
									LOG.info("removing " + name + ": error in validation.\n"
											+ e.getClass().getSimpleName() + ": " + e.getMessage());
									valErrors++;
									f.delete();
								}
							}
						}
						LOG.info(valErrors + failing + " scenarios removed.");

						// After cleaning problematic scenarios, collect scenario data
						LOG.info("Collecting test suite data...");
						try {
							avallaData = ScenarioDataCollector.collectAvallaData(dir);
							nScenario = ScenarioDataCollector.getNumberOfScenario(dir);
						} catch (Throwable t) {
							LOG.error("Error while collecting test suite data.\n" + t.getClass().getSimpleName() + ": "
									+ t.getMessage());
							status = STATUS.SCENARIO_DATA_ERROR;
							writeToCsv(csvManager, modelData, avallaData, covData, mutationData, asmName, asmPath,
									approach, status, execTime, nScenario, failing, valErrors);
							continue;
						}

						// If no correct scenario is generated
						int nStep = avallaData.get("n_step");
						if (Float.isNaN(execTime) || nScenario == 0 || nStep == 0) {
							LOG.info("No correct scenarios to use for running the analysis.");
							status = STATUS.NO_VALID_SCENARIOS;
							writeToCsv(csvManager, modelData, avallaData, covData, mutationData, asmName, asmPath,
									approach, status, execTime, nScenario, failing, valErrors);
							continue;
						}

						// Run validation to compute coverage, data is stored in a temporary CSV
						String tempCsvPath;
						int valErrorsAfterFiltering;
						try {
							LOG.info("Computing coverage (temporary results will be stored in temp.csv)...");
							tempCsvPath = csvManager.getParentDir() + File.separator + "temp.csv";
							valErrorsAfterFiltering = ScenarioValidator.computeCoverageFromAvalla(scenarioDir.getPath(),
									tempCsvPath, shuffle);
						} catch (Throwable t) {
							LOG.error("Error while computing coverage.\n" + t.getClass().getSimpleName() + ": "
									+ t.getMessage());
							status = STATUS.COVERAGE_ERROR;
							writeToCsv(csvManager, modelData, avallaData, covData, mutationData, asmName, asmPath,
									approach, status, execTime, nScenario, failing, valErrors);
							cleanTempCsv(csvManager);
							continue;
						} finally {
							// Reset rule evaluation state before the next suite
							RuleEvalWCov.reset();
						}

						// Aggregate coverage metrics from the temporary CSV
						try {
							LOG.info("Aggregating validation data...");
							covData = ValidationDataCollector.collectCoverageData(tempCsvPath, asmName, modelData);
						} catch (Throwable t) {
							LOG.error("Error while aggregating validation data.\n" + t.getClass().getSimpleName() + ": "
									+ t.getMessage());
							status = STATUS.DATA_AGGREGATION_ERROR;
							writeToCsv(csvManager, modelData, avallaData, covData, mutationData, asmName, asmPath,
									approach, status, execTime, nScenario, failing, valErrors);
							cleanTempCsv(csvManager);
							continue;
						}

						// Check no validation errors and no failing test cases
						if (valErrorsAfterFiltering > 0 || Integer.valueOf(covData.get("n_failing_scenarios")) > 0) {
							LOG.error("At least one scenario is still failing or resulting in validation error.");
							status = STATUS.REMAINING_PROBLEMATIC_SCENARIOS;
							writeToCsv(csvManager, modelData, avallaData, covData, mutationData, asmName, asmPath,
									approach, status, execTime, nScenario, failing, valErrors);
							cleanTempCsv(csvManager);
							continue;
						}

						// Run mutation
						try {
							LOG.info("Running mutation...");
							MutatedScenarioExecutor mutationExecutor = new MutatedScenarioExecutor();
							HashMap<String, List<AsmCollection>> allMutantions = mutationExecutor.generateMutants(asm);
							for (Entry<String, List<AsmCollection>> mutation : allMutantions.entrySet()) {
								String mutantionName = mutation.getKey().toLowerCase() + "_score";
								List<AsmCollection> mutatedAsms = mutation.getValue();
								int nMutants = mutatedAsms.size();
								if (nMutants > 0) {
									Set<Integer> killed = mutationExecutor.computeMutationScore(mutatedAsms,
											scenarioDir.getPath());
									float mutationScore = ((float) killed.size()) / nMutants;
									mutationData.put(mutantionName, String.valueOf(mutationScore));
								} else {
									mutationData.put(mutantionName, "NaN");
								}
							}
						} catch (Throwable t) {
							status = STATUS.MUTATION_ERROR;
							t.printStackTrace();
//							LOG.error("Error while running the mutation.\n" + t.getClass().getSimpleName() + ": "
//									+ t.getMessage());
						}

						// Append a consolidated row to data.csv
						writeToCsv(csvManager, modelData, avallaData, covData, mutationData, asmName, asmPath, approach,
								status, execTime, nScenario, failing, valErrors);

						// Clean the temporary CSV
						cleanTempCsv(csvManager);
					}
				}
			}
		}
		LOG.info("\n\nAnalysis completed.");
	}

	protected static void cleanTempCsv(CsvManager csvManager) {
		// Clean the temporary CSV
		try {
			LOG.info("Deleting temporary csv.");
			csvManager.clean();
		} catch (Throwable t) {
			LOG.error("Error while deleting temporary csv.\n" + t.getClass().getSimpleName() + ": "
					+ t.getMessage());
		}
	}

	private static void writeToCsv(CsvManager csvManager, Map<String, String> modelData,
			Map<String, Integer> avallaData, Map<String, String> covData, Map<String, String> mutationData,
			String asmName, String asmPath, String approach, STATUS status, float execTime, int nScenario, int failing,
			int valErrors) {
		try {
			LOG.info("Writing to " + DATA_CSV + ".");
			csvManager.writeData(modelData, avallaData, covData, mutationData, asmName, asmPath, approach, status,
					execTime, nScenario, failing, valErrors);
		} catch (Throwable t) {
			LOG.error("Error while writing to " + DATA_CSV + ".\n" + t.getClass().getSimpleName() + ": "
					+ t.getMessage());
		}
	}

}
